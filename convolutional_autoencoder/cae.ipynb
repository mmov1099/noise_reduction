{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "import torchvision.transforms.functional as tvF\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "from scripts.cdf import cdf2vlos_and_utc\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "# from tqdm import tqdm_notebook as tqdm\n",
    "from tqdm.notebook import tqdm\n",
    "import torch.nn.functional as F\n",
    "import seaborn as sns\n",
    "from ipywidgets import interact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_size: 667\n",
      "valid_size: 83\n",
      "test_size: 84\n"
     ]
    }
   ],
   "source": [
    "# データの準備\n",
    "data_dir_list = [\n",
    "    \"/home/miyazaki/Documents_ubuntu/noise_reduction/data/fitacf/hok/2017\",\n",
    "    \"/home/miyazaki/Documents_ubuntu/noise_reduction/data/fitacf/hok/2018\",\n",
    "    \"/home/miyazaki/Documents_ubuntu/noise_reduction/data/fitacf/hok/2019\",\n",
    "    \"/home/miyazaki/Documents_ubuntu/noise_reduction/data/fitacf/hok/2020\",\n",
    "    \"/home/miyazaki/Documents_ubuntu/noise_reduction/data/fitacf/kod/2021\",\n",
    "    ]\n",
    "\n",
    "data_path_list = []\n",
    "for data_dir in data_dir_list:\n",
    "    data_path_list += glob.glob(data_dir+\"/*.cdf\")\n",
    "\n",
    "random.seed(0)\n",
    "random.shuffle(data_path_list)\n",
    "\n",
    "train_size = int(len(data_path_list)*0.8)\n",
    "valid_size = int(len(data_path_list)*0.1)\n",
    "test_size = len(data_path_list) - train_size - valid_size\n",
    "\n",
    "train_data_path_list = data_path_list[:train_size]\n",
    "valid_data_path_list = data_path_list[train_size:train_size+valid_size]\n",
    "test_data_path_list = data_path_list[train_size+valid_size:]\n",
    "\n",
    "print(f\"train_size: {len(train_data_path_list)}\\nvalid_size: {len(valid_data_path_list)}\\ntest_size: {len(test_data_path_list)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, _ = cdf2vlos_and_utc(data_path_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c551f2978ba649b68ec33fd22f8cff64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/834 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_min = 0\n",
    "data_max = 0\n",
    "for data_path in tqdm(data_path_list):\n",
    "    data_, _ = cdf2vlos_and_utc(data_path)\n",
    "    data_min = min(data_min, data_.min())\n",
    "    data_max = max(data_max, data_[data_!=10000].max())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### creating dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data_path_list, chunk_size, data_min=None, data_max=None):\n",
    "        super(MyDataset, self).__init__()\n",
    "        self.data_path_list = data_path_list\n",
    "        self.h_max, self.w_max = self._find_hmax_and_wmax()\n",
    "\n",
    "        self.chunk_size = chunk_size\n",
    "\n",
    "        self.data_min = data_min\n",
    "        self.data_max = data_max\n",
    "\n",
    "\n",
    "    def _find_hmax_and_wmax(self):\n",
    "        h_max = 0\n",
    "        w_max = 0\n",
    "\n",
    "        for data_path in self.data_path_list:\n",
    "            data, _ = cdf2vlos_and_utc(data_path)\n",
    "            h_max = max(h_max, data.shape[0])\n",
    "            w_max = max(w_max, data.shape[1])\n",
    "\n",
    "        return h_max, w_max\n",
    "\n",
    "\n",
    "    def _padding(self, data):\n",
    "        # h_max = self.h_max\n",
    "        # w_max = self.w_max\n",
    "        target_h = 110\n",
    "        target_w = self.chunk_size\n",
    "\n",
    "        height, width = data.shape[:2]\n",
    "\n",
    "        target_size = (target_h, target_w)\n",
    "\n",
    "        padding_height = (target_size[0] - height)/2\n",
    "        padding_width = (target_size[1] - width)/2\n",
    "        value = 1.0000000e+04\n",
    "\n",
    "        if padding_height.is_integer():\n",
    "            top = bottom = int(padding_height)\n",
    "        else:\n",
    "            top = int(padding_height)\n",
    "            bottom = top + 1\n",
    "        if padding_width.is_integer():\n",
    "            left = right = int(padding_width)\n",
    "        else:\n",
    "            left = int(padding_width)\n",
    "            right = left + 1\n",
    "\n",
    "        data = np.pad(data, [(top, bottom), (left, right)], 'constant', constant_values=(value, value))\n",
    "\n",
    "        return data\n",
    "\n",
    "\n",
    "    def _get_data(self, index):\n",
    "        if index == 0:\n",
    "            self.file_index = 0\n",
    "            self.finished = True\n",
    "\n",
    "        if self.finished:\n",
    "            self.chunk_index = 0\n",
    "            data_path = self.data_path_list[self.file_index]\n",
    "            self.data, _ = cdf2vlos_and_utc(data_path)\n",
    "            self.splited_data = np.split(self.data, self.chunk_size, axis=0)\n",
    "            self.splited_data = [self.data[:,i:i+self.chunk_size] for i in range(0, self.data.shape[1], self.chunk_size)]\n",
    "            \n",
    "        else:\n",
    "            self.chunk_index += 1\n",
    "\n",
    "        if self.chunk_index == len(self.splited_data)-1 or self.splited_data[self.chunk_index].shape[1] < self.chunk_size:\n",
    "            self.finished = True\n",
    "            self.file_index += 1\n",
    "\n",
    "            return self._padding(self.splited_data[self.chunk_index])\n",
    "        \n",
    "        else:\n",
    "            self.finished = False\n",
    "\n",
    "            return self.splited_data[self.chunk_index]\n",
    "\n",
    "\n",
    "    def _normalize(self, data):\n",
    "        data[data==10000] = np.nan\n",
    "        data = (data - self.data_min)/(self.data_max - self.data_min)\n",
    "        data[np.isnan(data)] = 0\n",
    "\n",
    "        return data\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # data_path = self.data_path_list[index]\n",
    "        # data, _ = cdf2vlos_and_utc(data_path)\n",
    "        # data = self._padding(data)\n",
    "        data = self._get_data(index)\n",
    "        # data = self._normalize(data)\n",
    "        # print(\"datashape\",data.shape)\n",
    "\n",
    "        data = tvF.to_tensor(data)\n",
    "        \n",
    "        return data\n",
    "    \n",
    "\n",
    "    def __len__(self):\n",
    "        length = 0\n",
    "        for data_path in self.data_path_list:\n",
    "            data, _ = cdf2vlos_and_utc(data_path)\n",
    "            length += data.shape[1]//self.chunk_size\n",
    "            if data.shape[1]%self.chunk_size != 0:\n",
    "                length += 1\n",
    "\n",
    "        return length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StandardScalerSubset(Subset):\n",
    "    def __init__(self, dataset, indices, mean=None, std=None, eps=10**-9):\n",
    "        super().__init__(dataset=dataset, indices=indices)\n",
    "        target_tensor = torch.stack([dataset[i] for i in indices])\n",
    "        target_tensor = target_tensor.to(torch.float32)\n",
    "\n",
    "        if mean is None:\n",
    "            self._mean = torch.mean(target_tensor, dim=(0, 2, 3))\n",
    "        else:\n",
    "            self._mean = mean\n",
    "        if std is None:\n",
    "            self._std = torch.std(target_tensor, dim=(0, 2, 3), unbiased=False)\n",
    "        else:\n",
    "            self._std = std\n",
    "        self._eps = eps\n",
    "        self.std.apply_(lambda x: max(x, self.eps)) # ゼロ割対策\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        dataset = self.dataset[self.indices[idx]]\n",
    "        dataset = (dataset - self.mean) / self.std\n",
    "        return dataset\n",
    "\n",
    "    @property\n",
    "    def mean(self):\n",
    "        return self._mean\n",
    "\n",
    "    @property\n",
    "    def std(self):\n",
    "        return self._std\n",
    "\n",
    "    @property\n",
    "    def eps(self):\n",
    "        return self._eps"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### バッチサイズ、チャンクサイズ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130231\n",
      "16028\n",
      "15690\n"
     ]
    }
   ],
   "source": [
    "def load_dataset(data_path_list, batch_size, shuffle, chunk_size, mean=None, std=None, data_min=None, data_max=None):\n",
    "    dataset = MyDataset(data_path_list, chunk_size, data_min=data_min, data_max=data_max)\n",
    "    print(len(dataset))\n",
    "    # standart_scaler_subset = StandardScalerSubset(dataset, list(range(len(dataset))), mean=mean, std=std)\n",
    "    # mean = standart_scaler_subset.mean\n",
    "    # std = standart_scaler_subset.std\n",
    "\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle, num_workers=0)\n",
    "    return dataloader, mean, std\n",
    "\n",
    "batch_size = 128\n",
    "chunk_size = 110\n",
    "\n",
    "train_loader, mean, std = load_dataset(train_data_path_list, batch_size=batch_size, chunk_size=chunk_size, shuffle=False, data_min=data_min, data_max=data_max)\n",
    "valid_loader, _, _ = load_dataset(valid_data_path_list, batch_size=batch_size, chunk_size=chunk_size, shuffle=False, mean=mean, std=std, data_min=data_min, data_max=data_max)\n",
    "test_loader, _, _ = load_dataset(test_data_path_list, batch_size=batch_size, chunk_size=chunk_size, shuffle=False, mean=mean, std=std, data_min=data_min, data_max=data_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_data(data):\n",
    "    # mask=data==1.0000000e+04\n",
    "    fig, ax = plt.subplots(figsize=(10,2))\n",
    "    # sns.heatmap(data, cmap=\"jet\", mask=mask, vmax=500 ,vmin=-500)\n",
    "    sns.heatmap(data, cmap=\"jet\")\n",
    "    ax.invert_yaxis()\n",
    "    ax.set(ylabel='rgate_no_1')\n",
    "    ax.spines['right'].set_visible(True)\n",
    "    ax.spines['top'].set_visible(True)\n",
    "    ax.spines['left'].set_visible(True)\n",
    "    ax.spines['bottom'].set_visible(True)\n",
    "    ax.collections[0].colorbar.set_label('Doppler velocity[m/s]')\n",
    "    # ax.set(xticklabels=[])\n",
    "    # ax[0].tick_params(bottom=False)\n",
    "    # idxs = [int(xtick) for xtick in ax.get_xticks()]\n",
    "    # xlabels = [timestamp[idx] for idx in idxs]\n",
    "    # ax.set_xticklabels(xlabels)\n",
    "    ax.set(xlabel='epoch')\n",
    "    # plt.subplots_adjust(hspace=0.08)\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data showing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 2500x400 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1707ff6778af4ffb8792f6bc614111fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='idx', options=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 1…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.interact_func(idx)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataiter = iter(train_loader)\n",
    "datas = next(dataiter)\n",
    "datas = datas.numpy()\n",
    "\n",
    "fig = plt.figure(figsize=(25, 4))\n",
    "\n",
    "def interact_func(idx):\n",
    "    show_data(datas[idx].transpose(1,2,0).reshape(-1, chunk_size))\n",
    "\n",
    "interact(interact_func, idx=range(datas.shape[0]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataiter = iter(valid_loader)\n",
    "# datas = next(dataiter)\n",
    "# datas = datas.numpy()\n",
    "\n",
    "# fig = plt.figure(figsize=(25, 4))\n",
    "# def interact_func(idx):\n",
    "#     show_data(datas[idx].transpose(1,2,0).reshape(-1, chunk_size))\n",
    "\n",
    "# interact(interact_func, idx=range(datas.shape[0]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "    def __init__(self, in_channels=1, out_channels=1):\n",
    "        \"\"\"Initializes U-Net.\"\"\"\n",
    "\n",
    "        super(UNet, self).__init__()\n",
    "\n",
    "        # Layers: enc_conv0, enc_conv1, pool1\n",
    "        self._block1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, 48, 3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(48, 48, 3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2))\n",
    "\n",
    "        # Layers: enc_conv(i), pool(i); i=2..5\n",
    "        self._block2 = nn.Sequential(\n",
    "            nn.Conv2d(48, 48, 3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2))\n",
    "\n",
    "        # Layers: enc_conv6, upsample5\n",
    "        self._block3 = nn.Sequential(\n",
    "            nn.Conv2d(48, 48, 3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.ConvTranspose2d(48, 48, 3, stride=2, padding=1, output_padding=1))\n",
    "            #nn.Upsample(scale_factor=2, mode='nearest'))\n",
    "\n",
    "        # Layers: dec_conv5a, dec_conv5b, upsample4\n",
    "        self._block4 = nn.Sequential(\n",
    "            nn.Conv2d(96, 96, 3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(96, 96, 3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.ConvTranspose2d(96, 96, 4, stride=2, padding=1, output_padding=1))\n",
    "            #nn.Upsample(scale_factor=2, mode='nearest'))\n",
    "\n",
    "        # Layers: dec_deconv(i)a, dec_deconv(i)b, upsample(i-1); i=4..2\n",
    "        self._block5 = nn.Sequential(\n",
    "            nn.Conv2d(144, 96, 3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(96, 96, 3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.ConvTranspose2d(96, 96, 4, stride=2, padding=1, output_padding=1))\n",
    "            #nn.Upsample(scale_factor=2, mode='nearest'))\n",
    "\n",
    "        # Layers: dec_conv1a, dec_conv1b, dec_conv1c,\n",
    "        self._block6 = nn.Sequential(\n",
    "            nn.Conv2d(96 + in_channels, 64, 3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 32, 3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(32, out_channels, 3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.1)\n",
    "            # nn.Sigmoid())\n",
    "            # nn.Tanh())\n",
    "            # nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        self._block7 = nn.Sequential(\n",
    "            nn.Conv2d(144, 96, 3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(96, 96, 3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.ConvTranspose2d(96, 96, 4, stride=2, padding=1, output_padding=0))\n",
    "        \n",
    "        # Initialize weights\n",
    "        self._init_weights()\n",
    "\n",
    "\n",
    "    def _init_weights(self):\n",
    "        \"\"\"Initializes weights using He et al. (2015).\"\"\"\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.ConvTranspose2d) or isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight.data)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Through encoder, then decoder by adding U-skip connections. \"\"\"\n",
    "\n",
    "        # # Encoder\n",
    "        # pool1 = self._block1(x)\n",
    "        # pool2 = self._block2(pool1)\n",
    "        # pool3 = self._block2(pool2)\n",
    "\n",
    "        # # Decoder\n",
    "        # upsample3 = self._block3(pool3)\n",
    "        # concat3 = torch.cat((upsample3, pool2), dim=1)\n",
    "        # upsample2 = self._block4(concat3)\n",
    "        # concat2 = torch.cat((upsample2, pool1), dim=1)\n",
    "        # upsample1 = self._block5(concat2)\n",
    "        # concat1 = torch.cat((upsample1, x), dim=1)\n",
    "\n",
    "        # Encoder\n",
    "        pool1 = self._block1(x)\n",
    "        pool2 = self._block2(pool1)\n",
    "        pool3 = self._block2(pool2)\n",
    "        pool4 = self._block2(pool3)\n",
    "        pool5 = self._block2(pool4)\n",
    "\n",
    "        # Decoder\n",
    "        upsample5 = self._block3(pool5)\n",
    "        concat5 = torch.cat((upsample5, pool4), dim=1)\n",
    "        upsample4 = self._block4(concat5)\n",
    "        concat4 = torch.cat((upsample4, pool3), dim=1)\n",
    "        upsample3 = self._block5(concat4)\n",
    "        concat3 = torch.cat((upsample3, pool2), dim=1)\n",
    "        upsample2 = self._block5(concat3)\n",
    "        concat2 = torch.cat((upsample2, pool1), dim=1)\n",
    "        upsample1 = self._block7(concat2)\n",
    "        concat1 = torch.cat((upsample1, x), dim=1)\n",
    "\n",
    "        # Final activation\n",
    "        return self._block6(concat1)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class ConvAutoencoder(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(ConvAutoencoder, self).__init__()\n",
    "#         ## encoder layers ##\n",
    "#         # conv layer (depth from 3 --> 16), 3x3 kernels\n",
    "#         self.conv1 = nn.Conv2d(1, 16, 3, padding=1)  \n",
    "#         # conv layer (depth from 16 --> 4), 3x3 kernels\n",
    "#         self.conv2 = nn.Conv2d(16, 4, 3, padding=1)\n",
    "#         # pooling layer to reduce x-y dims by two; kernel and stride of 2\n",
    "#         self.pool = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "#         ## decoder layers ##\n",
    "#         ## a kernel of 2 and a stride of 2 will increase the spatial dims by 2\n",
    "#         self.t_conv1 = nn.ConvTranspose2d(4, 16, 3, stride=2)\n",
    "#         self.t_conv2 = nn.ConvTranspose2d(16, 1, 2, stride=2)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         ## encode ##\n",
    "#         # add hidden layers with relu activation function\n",
    "#         # and maxpooling after\n",
    "#         x = F.relu(self.conv1(x))\n",
    "#         x = self.pool(x)\n",
    "#         # add second hidden layer\n",
    "#         x = F.relu(self.conv2(x))\n",
    "#         x = self.pool(x)  # compressed representation\n",
    "        \n",
    "#         ## decode ##\n",
    "#         # add transpose conv layers, with relu activation function\n",
    "#         x = F.relu(self.t_conv1(x))\n",
    "#         # output layer (with sigmoid for scaling from 0 to 1)\n",
    "#         x = torch.sigmoid(self.t_conv2(x))\n",
    "                \n",
    "#         return x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CAE2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.autograd import Variable\n",
    "\n",
    "# class Reshape(nn.Module):\n",
    "#     def __init__(self, *args):\n",
    "#         super(Reshape, self).__init__()\n",
    "#         self.shape = args\n",
    "#     def forward(self,x):\n",
    "#         return x.view(self.shape)\n",
    "\n",
    "# def get_torch_vars(x):\n",
    "#     if torch.cuda.is_available():\n",
    "#         x = x.cuda()\n",
    "#     return Variable(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class ConvAutoencoder(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(ConvAutoencoder, self).__init__()\n",
    "#         self.encoder = nn.Sequential(\n",
    "#             nn.Conv2d(1, 16, kernel_size=3, stride=2, padding=1), nn.Tanh(),\n",
    "#             nn.Conv2d(16, 32, kernel_size=3, stride=2, padding=1), nn.Tanh(),\n",
    "#             nn.Conv2d(32, 32, kernel_size=3, stride=2, padding=1), nn.Tanh(),\n",
    "#             nn.Flatten(),\n",
    "#             nn.Linear(6272, 1024), nn.Tanh(), #6422528\n",
    "#         )\n",
    "\n",
    "#         self.decoder = nn.Sequential(\n",
    "#             nn.Linear(1024, 6272), nn.Tanh(),\n",
    "#             Reshape(-1, 32, 14, 14),\n",
    "#             nn.ConvTranspose2d(32, 32, kernel_size=4, stride=2, padding=1, output_padding=0), nn.Tanh(),\n",
    "#             nn.ConvTranspose2d(32, 16, kernel_size=4, stride=2, padding=1, output_padding=0), nn.Tanh(),\n",
    "#             nn.ConvTranspose2d(16, 1, kernel_size=4, stride=2, padding=2, output_padding=0), nn.Sigmoid(),\n",
    "#         )\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         z = self.encoder(x)\n",
    "#         x_pred = self.decoder(z)\n",
    "#         return x_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from lion_pytorch import Lion"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### traing settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_range = 110\n",
    "time_len = chunk_size\n",
    "input_size = num_range*time_len\n",
    "\n",
    "# model = ConvAutoencoder().to(device=\"cuda\")\n",
    "model = UNet().to(device=\"cuda\")\n",
    "# model.load_state_dict(torch.load('./model/epoch_100.pth'))\n",
    "# criterion = nn.L1Loss()\n",
    "criterion = nn.MSELoss()\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=0.03)\n",
    "optimizer = Lion(model.parameters(), lr=0.0001)\n",
    "scheduler = lr_scheduler.LinearLR(optimizer, start_factor=1.0, end_factor=0.05, total_iters=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\tTraining Loss: 705459.999509\tValidation Loss: 5520223.231151\tlr: 0.000099\n",
      "Epoch: 2\tTraining Loss: 121862.611416\tValidation Loss: 1006279.070312\tlr: 0.000098\n",
      "Epoch: 3\tTraining Loss: 23432.322285\tValidation Loss: 192708.335627\tlr: 0.000097\n",
      "Epoch: 4\tTraining Loss: 14482.576360\tValidation Loss: 118492.481585\tlr: 0.000096\n",
      "Epoch: 5\tTraining Loss: 11864.781373\tValidation Loss: 96552.500744\tlr: 0.000095\n",
      "Epoch: 6\tTraining Loss: 10686.281741\tValidation Loss: 86802.016555\tlr: 0.000094\n",
      "Epoch: 7\tTraining Loss: 9796.441414\tValidation Loss: 79438.151290\tlr: 0.000093\n",
      "Epoch: 8\tTraining Loss: 8780.663940\tValidation Loss: 71167.265470\tlr: 0.000092\n",
      "Epoch: 9\tTraining Loss: 7664.014278\tValidation Loss: 62105.777499\tlr: 0.000091\n",
      "Epoch: 10\tTraining Loss: 6630.814580\tValidation Loss: 53738.558377\tlr: 0.000091\n",
      "Epoch: 11\tTraining Loss: 5741.232226\tValidation Loss: 46550.431858\tlr: 0.000090\n",
      "Epoch: 12\tTraining Loss: 5002.392781\tValidation Loss: 40578.300099\tlr: 0.000089\n",
      "Epoch: 13\tTraining Loss: 4387.005510\tValidation Loss: 35614.429594\tlr: 0.000088\n",
      "Epoch: 14\tTraining Loss: 3879.881320\tValidation Loss: 31520.839689\tlr: 0.000087\n",
      "Epoch: 15\tTraining Loss: 3474.997863\tValidation Loss: 28251.426432\tlr: 0.000086\n",
      "Epoch: 16\tTraining Loss: 3159.610889\tValidation Loss: 25706.184353\tlr: 0.000085\n",
      "Epoch: 17\tTraining Loss: 2909.468353\tValidation Loss: 23684.935330\tlr: 0.000084\n",
      "Epoch: 18\tTraining Loss: 2711.708731\tValidation Loss: 22082.774073\tlr: 0.000083\n",
      "Epoch: 19\tTraining Loss: 2557.267584\tValidation Loss: 20845.816499\tlr: 0.000082\n",
      "Epoch: 20\tTraining Loss: 2442.904197\tValidation Loss: 19918.108569\tlr: 0.000081\n",
      "Epoch: 21\tTraining Loss: 2355.291428\tValidation Loss: 19211.050843\tlr: 0.000080\n",
      "Epoch: 22\tTraining Loss: 2281.180263\tValidation Loss: 18607.419705\tlr: 0.000079\n",
      "Epoch: 23\tTraining Loss: 2216.726717\tValidation Loss: 18090.758154\tlr: 0.000078\n",
      "Epoch: 24\tTraining Loss: 2161.914005\tValidation Loss: 17645.088813\tlr: 0.000077\n",
      "Epoch: 25\tTraining Loss: 2113.269117\tValidation Loss: 17249.283668\tlr: 0.000076\n",
      "Epoch: 26\tTraining Loss: 2070.519823\tValidation Loss: 16904.242792\tlr: 0.000075\n",
      "Epoch: 27\tTraining Loss: 2030.503725\tValidation Loss: 16578.241335\tlr: 0.000074\n",
      "Epoch: 28\tTraining Loss: 1991.965123\tValidation Loss: 16265.880216\tlr: 0.000073\n",
      "Epoch: 29\tTraining Loss: 1957.624896\tValidation Loss: 15987.425394\tlr: 0.000072\n"
     ]
    }
   ],
   "source": [
    "# number of epochs to train the model\n",
    "n_epochs = 100\n",
    "train_losses = []\n",
    "valid_losses = []\n",
    "alpha = 1 # 正則化パラメータ\n",
    "\n",
    "def calc_li_loss(model, loss):\n",
    "    # パラメータのL1ノルムを損失関数に足す\n",
    "    l1 = torch.tensor(0., requires_grad=True)\n",
    "    for w in model.parameters():\n",
    "        l1 = l1 + torch.norm(w, 1)\n",
    "    l1_loss = loss + alpha*l1\n",
    "    return l1_loss\n",
    "\n",
    "\n",
    "for epoch in range(1, n_epochs+1):\n",
    "    train_batch_loss = 0.0\n",
    "    valid_batch_loss = 0.0\n",
    "    \n",
    "    for train_batch, valid_batch in zip(train_loader, valid_loader):\n",
    "        model.train()\n",
    "        data = train_batch.to(device=\"cuda\")\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(data)\n",
    "\n",
    "        train_loss = criterion(outputs, data)\n",
    "        l1_train_loss = calc_li_loss(model, train_loss)\n",
    "        l1_train_loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        train_batch_loss += l1_train_loss.item()\n",
    "\n",
    "        model.eval()\n",
    "        data = valid_batch.to(device=\"cuda\")\n",
    "        outputs = model(data)\n",
    "        valid_loss = criterion(outputs, data)\n",
    "        l1_valid_loss = calc_li_loss(model, valid_loss)\n",
    "        valid_batch_loss += l1_valid_loss.item()\n",
    "            \n",
    "    scheduler.step()\n",
    "\n",
    "    train_loss_avg = train_batch_loss/len(train_loader)\n",
    "    valid_loss_avg = valid_batch_loss/len(valid_loader)\n",
    "    train_losses.append(train_loss_avg)\n",
    "    valid_losses.append(valid_loss_avg)\n",
    "\n",
    "    # clear_output(wait=True)\n",
    "    print(f'Epoch: {epoch}\\tTraining Loss: {train_loss_avg:.6f}\\tValidation Loss: {valid_loss_avg:.6f}\\tlr: {optimizer.param_groups[0][\"lr\"]:.6f}')\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "        torch.save(model.state_dict(), f'./model/epoch_{epoch}.pth')\n",
    "\n",
    "        plt.plot(train_losses, label='Training loss')\n",
    "        plt.savefig(f'./model/train_loss_epoch_{epoch}.png')\n",
    "        plt.close()\n",
    "\n",
    "        plt.plot(valid_losses, label='Validation loss')\n",
    "        plt.savefig(f'./model/valid_loss_epoch_{epoch}.png')\n",
    "        plt.close()\n",
    "\n",
    "        plt.plot(train_losses, label='Training loss')\n",
    "        plt.plot(valid_losses, label='Validation loss')\n",
    "        plt.legend(frameon=False)\n",
    "        plt.savefig(f'./model/epoch_{epoch}.png')\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the training loss\n",
    "plt.plot(range(1, n_epochs+1), train_losses, label='Train')\n",
    "plt.plot(range(1, n_epochs+1), valid_losses, label='Valid')\n",
    "plt.xlabel(\"Number of epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_losses = 0\n",
    "for test_batch in test_loader:\n",
    "    model.eval()\n",
    "    data = test_batch.to(device=\"cuda\")\n",
    "    outputs = model(data)\n",
    "    test_loss = criterion(outputs, data)\n",
    "    test_losses += test_loss.item()\n",
    "print(f\"Test loss: {test_losses/len(test_loader):.6f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(train_loader)\n",
    "datas = next(dataiter)\n",
    "\n",
    "model.eval()\n",
    "data = datas.to(device=\"cuda\")\n",
    "outputs = model(data)\n",
    "\n",
    "datas = datas.cpu().detach().numpy()\n",
    "outputs = outputs.cpu().detach().numpy()\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(25, 4))\n",
    "def interact_func(idx):\n",
    "    show_data(datas[idx].transpose(1,2,0).reshape(-1, chunk_size))\n",
    "    show_data(outputs[idx].transpose(1,2,0).reshape(-1, chunk_size))\n",
    "\n",
    "interact(interact_func, idx=range(datas.shape[0]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(test_loader)\n",
    "datas = next(dataiter)\n",
    "\n",
    "model.eval()\n",
    "data = datas.to(device=\"cuda\")\n",
    "outputs = model(data)\n",
    "\n",
    "datas = datas.cpu().detach().numpy()\n",
    "outputs = outputs.cpu().detach().numpy()\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(25, 4))\n",
    "\n",
    "def interact_func(idx):\n",
    "    show_data(datas[idx].transpose(1,2,0).reshape(-1, chunk_size))\n",
    "    show_data(outputs[idx].transpose(1,2,0).reshape(-1, chunk_size))\n",
    "\n",
    "interact(interact_func, idx=range(datas.shape[0]))\n",
    "\n",
    "# for idx in np.arange(5):\n",
    "#     show_data(datas[idx].transpose(1,2,0).reshape(-1,110))\n",
    "#     show_data(outputs[idx].transpose(1,2,0).reshape(-1,110))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs[outputs!=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "noise_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
