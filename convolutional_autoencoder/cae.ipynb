{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "import torchvision.transforms.functional as tvF\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "from scripts.cdf import cdf2vlos_and_utc\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "# from tqdm import tqdm_notebook as tqdm\n",
    "from tqdm.notebook import tqdm\n",
    "import torch.nn.functional as F\n",
    "import seaborn as sns\n",
    "from ipywidgets import interact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_size: 667\n",
      "valid_size: 83\n",
      "test_size: 84\n"
     ]
    }
   ],
   "source": [
    "# データの準備\n",
    "data_dir_list = [\n",
    "    \"/home/miyazaki/Documents_ubuntu/noise_reduction/data/fitacf/hok/2017\",\n",
    "    \"/home/miyazaki/Documents_ubuntu/noise_reduction/data/fitacf/hok/2018\",\n",
    "    \"/home/miyazaki/Documents_ubuntu/noise_reduction/data/fitacf/hok/2019\",\n",
    "    \"/home/miyazaki/Documents_ubuntu/noise_reduction/data/fitacf/hok/2020\",\n",
    "    \"/home/miyazaki/Documents_ubuntu/noise_reduction/data/fitacf/kod/2021\",\n",
    "    ]\n",
    "\n",
    "data_path_list = []\n",
    "for data_dir in data_dir_list:\n",
    "    data_path_list += glob.glob(data_dir+\"/*.cdf\")\n",
    "\n",
    "random.seed(0)\n",
    "random.shuffle(data_path_list)\n",
    "\n",
    "train_size = int(len(data_path_list)*0.8)\n",
    "valid_size = int(len(data_path_list)*0.1)\n",
    "test_size = len(data_path_list) - train_size - valid_size\n",
    "\n",
    "train_data_path_list = data_path_list[:train_size]\n",
    "valid_data_path_list = data_path_list[train_size:train_size+valid_size]\n",
    "test_data_path_list = data_path_list[train_size+valid_size:]\n",
    "\n",
    "print(f\"train_size: {len(train_data_path_list)}\\nvalid_size: {len(valid_data_path_list)}\\ntest_size: {len(test_data_path_list)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, _ = cdf2vlos_and_utc(data_path_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1acfd45008ef4950969beb84d54c16fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/834 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_min = 0\n",
    "data_max = 0\n",
    "for data_path in tqdm(data_path_list):\n",
    "    data_, _ = cdf2vlos_and_utc(data_path)\n",
    "    data_min = min(data_min, data_.min())\n",
    "    data_max = max(data_max, data_[data_!=10000].max())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### creating dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data_path_list, chunk_size, data_min=None, data_max=None):\n",
    "        super(MyDataset, self).__init__()\n",
    "        self.data_path_list = data_path_list\n",
    "        self.h_max, self.w_max = self._find_hmax_and_wmax()\n",
    "\n",
    "        self.chunk_size = chunk_size\n",
    "\n",
    "        self.data_min = data_min\n",
    "        self.data_max = data_max\n",
    "\n",
    "\n",
    "    def _find_hmax_and_wmax(self):\n",
    "        h_max = 0\n",
    "        w_max = 0\n",
    "\n",
    "        for data_path in self.data_path_list:\n",
    "            data, _ = cdf2vlos_and_utc(data_path)\n",
    "            h_max = max(h_max, data.shape[0])\n",
    "            w_max = max(w_max, data.shape[1])\n",
    "\n",
    "        return h_max, w_max\n",
    "\n",
    "\n",
    "    def _padding(self, data):\n",
    "        # h_max = self.h_max\n",
    "        # w_max = self.w_max\n",
    "        target_h = 110\n",
    "        target_w = self.chunk_size\n",
    "\n",
    "        height, width = data.shape[:2]\n",
    "\n",
    "        target_size = (target_h, target_w)\n",
    "\n",
    "        padding_height = (target_size[0] - height)/2\n",
    "        padding_width = (target_size[1] - width)/2\n",
    "        value = 1.0000000e+04\n",
    "\n",
    "        if padding_height.is_integer():\n",
    "            top = bottom = int(padding_height)\n",
    "        else:\n",
    "            top = int(padding_height)\n",
    "            bottom = top + 1\n",
    "        if padding_width.is_integer():\n",
    "            left = right = int(padding_width)\n",
    "        else:\n",
    "            left = int(padding_width)\n",
    "            right = left + 1\n",
    "\n",
    "        data = np.pad(data, [(top, bottom), (left, right)], 'constant', constant_values=(value, value))\n",
    "\n",
    "        return data\n",
    "\n",
    "\n",
    "    def _get_data(self, index):\n",
    "        if index == 0:\n",
    "            self.file_index = 0\n",
    "            self.finished = True\n",
    "\n",
    "        if self.finished:\n",
    "            self.chunk_index = 0\n",
    "            data_path = self.data_path_list[self.file_index]\n",
    "            self.data, _ = cdf2vlos_and_utc(data_path)\n",
    "            self.splited_data = np.split(self.data, self.chunk_size, axis=0)\n",
    "            self.splited_data = [self.data[:,i:i+self.chunk_size] for i in range(0, self.data.shape[1], self.chunk_size)]\n",
    "            \n",
    "        else:\n",
    "            self.chunk_index += 1\n",
    "\n",
    "        if self.chunk_index == len(self.splited_data)-1 or self.splited_data[self.chunk_index].shape[1] < self.chunk_size:\n",
    "            self.finished = True\n",
    "            self.file_index += 1\n",
    "\n",
    "            return self._padding(self.splited_data[self.chunk_index])\n",
    "        \n",
    "        else:\n",
    "            self.finished = False\n",
    "\n",
    "            return self.splited_data[self.chunk_index]\n",
    "\n",
    "\n",
    "    def _normalize(self, data):\n",
    "        data[data==10000] = np.nan\n",
    "        data = (data - self.data_min)/(self.data_max - self.data_min)\n",
    "        data[np.isnan(data)] = 0\n",
    "\n",
    "        return data\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # data_path = self.data_path_list[index]\n",
    "        # data, _ = cdf2vlos_and_utc(data_path)\n",
    "        # data = self._padding(data)\n",
    "        data = self._get_data(index)\n",
    "        data = self._normalize(data)\n",
    "        # print(\"datashape\",data.shape)\n",
    "\n",
    "        data = tvF.to_tensor(data)\n",
    "        \n",
    "        return data\n",
    "    \n",
    "\n",
    "    def __len__(self):\n",
    "        length = 0\n",
    "        for data_path in self.data_path_list:\n",
    "            data, _ = cdf2vlos_and_utc(data_path)\n",
    "            length += data.shape[1]//self.chunk_size\n",
    "            if data.shape[1]%self.chunk_size != 0:\n",
    "                length += 1\n",
    "\n",
    "        return length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StandardScalerSubset(Subset):\n",
    "    def __init__(self, dataset, indices, mean=None, std=None, eps=10**-9):\n",
    "        super().__init__(dataset=dataset, indices=indices)\n",
    "        target_tensor = torch.stack([dataset[i] for i in indices])\n",
    "        target_tensor = target_tensor.to(torch.float32)\n",
    "\n",
    "        if mean is None:\n",
    "            self._mean = torch.mean(target_tensor, dim=(0, 2, 3))\n",
    "        else:\n",
    "            self._mean = mean\n",
    "        if std is None:\n",
    "            self._std = torch.std(target_tensor, dim=(0, 2, 3), unbiased=False)\n",
    "        else:\n",
    "            self._std = std\n",
    "        self._eps = eps\n",
    "        self.std.apply_(lambda x: max(x, self.eps)) # ゼロ割対策\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        dataset = self.dataset[self.indices[idx]]\n",
    "        dataset = (dataset - self.mean) / self.std\n",
    "        return dataset\n",
    "\n",
    "    @property\n",
    "    def mean(self):\n",
    "        return self._mean\n",
    "\n",
    "    @property\n",
    "    def std(self):\n",
    "        return self._std\n",
    "\n",
    "    @property\n",
    "    def eps(self):\n",
    "        return self._eps"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### バッチサイズ、チャンクサイズ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130231\n",
      "16028\n",
      "15690\n"
     ]
    }
   ],
   "source": [
    "def load_dataset(data_path_list, batch_size, shuffle, chunk_size, mean=None, std=None, data_min=None, data_max=None):\n",
    "    dataset = MyDataset(data_path_list, chunk_size, data_min=data_min, data_max=data_max)\n",
    "    print(len(dataset))\n",
    "    # standart_scaler_subset = StandardScalerSubset(dataset, list(range(len(dataset))), mean=mean, std=std)\n",
    "    # mean = standart_scaler_subset.mean\n",
    "    # std = standart_scaler_subset.std\n",
    "\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle, num_workers=0)\n",
    "    return dataloader, mean, std\n",
    "\n",
    "batch_size = 256\n",
    "chunk_size = 110\n",
    "\n",
    "train_loader, mean, std = load_dataset(train_data_path_list, batch_size=batch_size, chunk_size=chunk_size, shuffle=False, data_min=data_min, data_max=data_max)\n",
    "valid_loader, _, _ = load_dataset(valid_data_path_list, batch_size=batch_size, chunk_size=chunk_size, shuffle=False, mean=mean, std=std, data_min=data_min, data_max=data_max)\n",
    "test_loader, _, _ = load_dataset(test_data_path_list, batch_size=batch_size, chunk_size=chunk_size, shuffle=False, mean=mean, std=std, data_min=data_min, data_max=data_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_data(data):\n",
    "    # mask=data==1.0000000e+04\n",
    "    fig, ax = plt.subplots(figsize=(10,2))\n",
    "    # sns.heatmap(data, cmap=\"jet\", mask=mask, vmax=500 ,vmin=-500)\n",
    "    sns.heatmap(data, cmap=\"jet\")\n",
    "    ax.invert_yaxis()\n",
    "    ax.set(ylabel='rgate_no_1')\n",
    "    ax.spines['right'].set_visible(True)\n",
    "    ax.spines['top'].set_visible(True)\n",
    "    ax.spines['left'].set_visible(True)\n",
    "    ax.spines['bottom'].set_visible(True)\n",
    "    ax.collections[0].colorbar.set_label('Doppler velocity[m/s]')\n",
    "    # ax.set(xticklabels=[])\n",
    "    # ax[0].tick_params(bottom=False)\n",
    "    # idxs = [int(xtick) for xtick in ax.get_xticks()]\n",
    "    # xlabels = [timestamp[idx] for idx in idxs]\n",
    "    # ax.set_xticklabels(xlabels)\n",
    "    ax.set(xlabel='epoch')\n",
    "    # plt.subplots_adjust(hspace=0.08)\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data showing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 2500x400 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fad2326773d34dd091340435fab08a84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='idx', options=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 1…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.interact_func(idx)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataiter = iter(train_loader)\n",
    "datas = next(dataiter)\n",
    "datas = datas.numpy()\n",
    "\n",
    "fig = plt.figure(figsize=(25, 4))\n",
    "\n",
    "def interact_func(idx):\n",
    "    show_data(datas[idx].transpose(1,2,0).reshape(-1, chunk_size))\n",
    "\n",
    "interact(interact_func, idx=range(datas.shape[0]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataiter = iter(valid_loader)\n",
    "# datas = next(dataiter)\n",
    "# datas = datas.numpy()\n",
    "\n",
    "# fig = plt.figure(figsize=(25, 4))\n",
    "# def interact_func(idx):\n",
    "#     show_data(datas[idx].transpose(1,2,0).reshape(-1, chunk_size))\n",
    "\n",
    "# interact(interact_func, idx=range(datas.shape[0]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "    def __init__(self, in_channels=1, out_channels=1):\n",
    "        \"\"\"Initializes U-Net.\"\"\"\n",
    "\n",
    "        super(UNet, self).__init__()\n",
    "\n",
    "        # Layers: enc_conv0, enc_conv1, pool1\n",
    "        self._block1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, 48, 3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(48, 48, 3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2))\n",
    "\n",
    "        # Layers: enc_conv(i), pool(i); i=2..5\n",
    "        self._block2 = nn.Sequential(\n",
    "            nn.Conv2d(48, 48, 3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2))\n",
    "\n",
    "        # Layers: enc_conv6, upsample5\n",
    "        self._block3 = nn.Sequential(\n",
    "            nn.Conv2d(48, 48, 3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.ConvTranspose2d(48, 48, 3, stride=2, padding=1, output_padding=1))\n",
    "            #nn.Upsample(scale_factor=2, mode='nearest'))\n",
    "\n",
    "        # Layers: dec_conv5a, dec_conv5b, upsample4\n",
    "        self._block4 = nn.Sequential(\n",
    "            nn.Conv2d(96, 96, 3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(96, 96, 3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.ConvTranspose2d(96, 96, 4, stride=2, padding=1, output_padding=1))\n",
    "            #nn.Upsample(scale_factor=2, mode='nearest'))\n",
    "\n",
    "        # Layers: dec_deconv(i)a, dec_deconv(i)b, upsample(i-1); i=4..2\n",
    "        self._block5 = nn.Sequential(\n",
    "            nn.Conv2d(144, 96, 3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(96, 96, 3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.ConvTranspose2d(96, 96, 4, stride=2, padding=1, output_padding=1))\n",
    "            #nn.Upsample(scale_factor=2, mode='nearest'))\n",
    "\n",
    "        # Layers: dec_conv1a, dec_conv1b, dec_conv1c,\n",
    "        self._block6 = nn.Sequential(\n",
    "            nn.Conv2d(96 + in_channels, 64, 3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 32, 3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(32, out_channels, 3, stride=1, padding=1),\n",
    "            # nn.LeakyReLU(0.1))\n",
    "            # nn.Sigmoid())\n",
    "            nn.Tanh())\n",
    "        \n",
    "        self._block7 = nn.Sequential(\n",
    "            nn.Conv2d(144, 96, 3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(96, 96, 3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.ConvTranspose2d(96, 96, 4, stride=2, padding=1, output_padding=0))\n",
    "        \n",
    "        # Initialize weights\n",
    "        self._init_weights()\n",
    "\n",
    "\n",
    "    def _init_weights(self):\n",
    "        \"\"\"Initializes weights using He et al. (2015).\"\"\"\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.ConvTranspose2d) or isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight.data)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Through encoder, then decoder by adding U-skip connections. \"\"\"\n",
    "\n",
    "        # # Encoder\n",
    "        # pool1 = self._block1(x)\n",
    "        # pool2 = self._block2(pool1)\n",
    "        # pool3 = self._block2(pool2)\n",
    "\n",
    "        # # Decoder\n",
    "        # upsample3 = self._block3(pool3)\n",
    "        # concat3 = torch.cat((upsample3, pool2), dim=1)\n",
    "        # upsample2 = self._block4(concat3)\n",
    "        # concat2 = torch.cat((upsample2, pool1), dim=1)\n",
    "        # upsample1 = self._block5(concat2)\n",
    "        # concat1 = torch.cat((upsample1, x), dim=1)\n",
    "\n",
    "        # Encoder\n",
    "        pool1 = self._block1(x)\n",
    "        pool2 = self._block2(pool1)\n",
    "        pool3 = self._block2(pool2)\n",
    "        pool4 = self._block2(pool3)\n",
    "        pool5 = self._block2(pool4)\n",
    "\n",
    "        # Decoder\n",
    "        upsample5 = self._block3(pool5)\n",
    "        concat5 = torch.cat((upsample5, pool4), dim=1)\n",
    "        upsample4 = self._block4(concat5)\n",
    "        concat4 = torch.cat((upsample4, pool3), dim=1)\n",
    "        upsample3 = self._block5(concat4)\n",
    "        concat3 = torch.cat((upsample3, pool2), dim=1)\n",
    "        upsample2 = self._block5(concat3)\n",
    "        concat2 = torch.cat((upsample2, pool1), dim=1)\n",
    "        upsample1 = self._block7(concat2)\n",
    "        concat1 = torch.cat((upsample1, x), dim=1)\n",
    "\n",
    "        # Final activation\n",
    "        return self._block6(concat1)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class ConvAutoencoder(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(ConvAutoencoder, self).__init__()\n",
    "#         ## encoder layers ##\n",
    "#         # conv layer (depth from 3 --> 16), 3x3 kernels\n",
    "#         self.conv1 = nn.Conv2d(1, 16, 3, padding=1)  \n",
    "#         # conv layer (depth from 16 --> 4), 3x3 kernels\n",
    "#         self.conv2 = nn.Conv2d(16, 4, 3, padding=1)\n",
    "#         # pooling layer to reduce x-y dims by two; kernel and stride of 2\n",
    "#         self.pool = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "#         ## decoder layers ##\n",
    "#         ## a kernel of 2 and a stride of 2 will increase the spatial dims by 2\n",
    "#         self.t_conv1 = nn.ConvTranspose2d(4, 16, 3, stride=2)\n",
    "#         self.t_conv2 = nn.ConvTranspose2d(16, 1, 2, stride=2)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         ## encode ##\n",
    "#         # add hidden layers with relu activation function\n",
    "#         # and maxpooling after\n",
    "#         x = F.relu(self.conv1(x))\n",
    "#         x = self.pool(x)\n",
    "#         # add second hidden layer\n",
    "#         x = F.relu(self.conv2(x))\n",
    "#         x = self.pool(x)  # compressed representation\n",
    "        \n",
    "#         ## decode ##\n",
    "#         # add transpose conv layers, with relu activation function\n",
    "#         x = F.relu(self.t_conv1(x))\n",
    "#         # output layer (with sigmoid for scaling from 0 to 1)\n",
    "#         x = torch.sigmoid(self.t_conv2(x))\n",
    "                \n",
    "#         return x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CAE2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.autograd import Variable\n",
    "\n",
    "# class Reshape(nn.Module):\n",
    "#     def __init__(self, *args):\n",
    "#         super(Reshape, self).__init__()\n",
    "#         self.shape = args\n",
    "#     def forward(self,x):\n",
    "#         return x.view(self.shape)\n",
    "\n",
    "# def get_torch_vars(x):\n",
    "#     if torch.cuda.is_available():\n",
    "#         x = x.cuda()\n",
    "#     return Variable(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class ConvAutoencoder(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(ConvAutoencoder, self).__init__()\n",
    "#         self.encoder = nn.Sequential(\n",
    "#             nn.Conv2d(1, 16, kernel_size=3, stride=2, padding=1), nn.Tanh(),\n",
    "#             nn.Conv2d(16, 32, kernel_size=3, stride=2, padding=1), nn.Tanh(),\n",
    "#             nn.Conv2d(32, 32, kernel_size=3, stride=2, padding=1), nn.Tanh(),\n",
    "#             nn.Flatten(),\n",
    "#             nn.Linear(6272, 1024), nn.Tanh(), #6422528\n",
    "#         )\n",
    "\n",
    "#         self.decoder = nn.Sequential(\n",
    "#             nn.Linear(1024, 6272), nn.Tanh(),\n",
    "#             Reshape(-1, 32, 14, 14),\n",
    "#             nn.ConvTranspose2d(32, 32, kernel_size=4, stride=2, padding=1, output_padding=0), nn.Tanh(),\n",
    "#             nn.ConvTranspose2d(32, 16, kernel_size=4, stride=2, padding=1, output_padding=0), nn.Tanh(),\n",
    "#             nn.ConvTranspose2d(16, 1, kernel_size=4, stride=2, padding=2, output_padding=0), nn.Sigmoid(),\n",
    "#         )\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         z = self.encoder(x)\n",
    "#         x_pred = self.decoder(z)\n",
    "#         return x_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from lion_pytorch import Lion"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### traing settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_range = 110\n",
    "time_len = chunk_size\n",
    "input_size = num_range*time_len\n",
    "\n",
    "# model = ConvAutoencoder().to(device=\"cuda\")\n",
    "model = UNet().to(device=\"cuda\")\n",
    "# model.load_state_dict(torch.load('./model/'))\n",
    "# criterion = nn.L1Loss()\n",
    "criterion = nn.MSELoss()\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=0.03)\n",
    "optimizer = Lion(model.parameters(), lr=0.0001)\n",
    "scheduler = lr_scheduler.LinearLR(optimizer, start_factor=1.0, end_factor=0.05, total_iters=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\tTraining Loss: 4638.887977\tValidation Loss: 37369.396329\tlr: 0.000099\n",
      "Epoch: 2\tTraining Loss: 3846.841666\tValidation Loss: 30986.624349\tlr: 0.000098\n",
      "Epoch: 3\tTraining Loss: 3173.466225\tValidation Loss: 25560.127976\tlr: 0.000097\n",
      "Epoch: 4\tTraining Loss: 2600.560393\tValidation Loss: 20943.359561\tlr: 0.000096\n",
      "Epoch: 5\tTraining Loss: 2115.353679\tValidation Loss: 17033.696212\tlr: 0.000095\n",
      "Epoch: 6\tTraining Loss: 1707.082012\tValidation Loss: 13744.495117\tlr: 0.000094\n",
      "Epoch: 7\tTraining Loss: 1367.834758\tValidation Loss: 11011.828389\tlr: 0.000093\n",
      "Epoch: 8\tTraining Loss: 1089.528010\tValidation Loss: 8770.568483\tlr: 0.000092\n",
      "Epoch: 9\tTraining Loss: 863.494839\tValidation Loss: 6950.704729\tlr: 0.000091\n",
      "Epoch: 10\tTraining Loss: 682.625214\tValidation Loss: 5494.518012\tlr: 0.000091\n",
      "Epoch: 11\tTraining Loss: 538.583910\tValidation Loss: 4335.018268\tlr: 0.000090\n",
      "Epoch: 12\tTraining Loss: 424.545999\tValidation Loss: 3417.170216\tlr: 0.000089\n",
      "Epoch: 13\tTraining Loss: 335.275336\tValidation Loss: 2698.729225\tlr: 0.000088\n",
      "Epoch: 14\tTraining Loss: 265.431890\tValidation Loss: 2136.652572\tlr: 0.000087\n",
      "Epoch: 15\tTraining Loss: 211.155254\tValidation Loss: 1699.895884\tlr: 0.000086\n",
      "Epoch: 16\tTraining Loss: 168.904143\tValidation Loss: 1359.883305\tlr: 0.000085\n",
      "Epoch: 17\tTraining Loss: 136.197535\tValidation Loss: 1096.724543\tlr: 0.000084\n",
      "Epoch: 18\tTraining Loss: 110.815931\tValidation Loss: 892.454065\tlr: 0.000083\n",
      "Epoch: 19\tTraining Loss: 90.998080\tValidation Loss: 732.984411\tlr: 0.000082\n",
      "Epoch: 20\tTraining Loss: 75.611837\tValidation Loss: 609.158394\tlr: 0.000081\n",
      "Epoch: 21\tTraining Loss: 63.569753\tValidation Loss: 512.241973\tlr: 0.000080\n",
      "Epoch: 22\tTraining Loss: 54.050869\tValidation Loss: 435.615337\tlr: 0.000079\n",
      "Epoch: 23\tTraining Loss: 46.633810\tValidation Loss: 375.941281\tlr: 0.000078\n",
      "Epoch: 24\tTraining Loss: 40.808940\tValidation Loss: 329.042875\tlr: 0.000077\n",
      "Epoch: 25\tTraining Loss: 36.141464\tValidation Loss: 291.468366\tlr: 0.000076\n",
      "Epoch: 26\tTraining Loss: 32.376937\tValidation Loss: 261.153441\tlr: 0.000075\n",
      "Epoch: 27\tTraining Loss: 29.396351\tValidation Loss: 237.167279\tlr: 0.000074\n",
      "Epoch: 28\tTraining Loss: 26.986370\tValidation Loss: 217.752459\tlr: 0.000073\n",
      "Epoch: 29\tTraining Loss: 25.019764\tValidation Loss: 201.918862\tlr: 0.000072\n",
      "Epoch: 30\tTraining Loss: 23.403160\tValidation Loss: 188.893796\tlr: 0.000072\n",
      "Epoch: 31\tTraining Loss: 22.060652\tValidation Loss: 178.081008\tlr: 0.000071\n",
      "Epoch: 32\tTraining Loss: 20.930220\tValidation Loss: 168.969713\tlr: 0.000070\n",
      "Epoch: 33\tTraining Loss: 19.987801\tValidation Loss: 161.379811\tlr: 0.000069\n",
      "Epoch: 34\tTraining Loss: 19.191314\tValidation Loss: 154.959240\tlr: 0.000068\n",
      "Epoch: 35\tTraining Loss: 18.513714\tValidation Loss: 149.500766\tlr: 0.000067\n",
      "Epoch: 36\tTraining Loss: 17.926930\tValidation Loss: 144.766697\tlr: 0.000066\n",
      "Epoch: 37\tTraining Loss: 17.413104\tValidation Loss: 140.627729\tlr: 0.000065\n",
      "Epoch: 38\tTraining Loss: 16.961064\tValidation Loss: 136.978831\tlr: 0.000064\n",
      "Epoch: 39\tTraining Loss: 16.558296\tValidation Loss: 133.733831\tlr: 0.000063\n",
      "Epoch: 40\tTraining Loss: 16.198212\tValidation Loss: 130.827168\tlr: 0.000062\n",
      "Epoch: 41\tTraining Loss: 15.876393\tValidation Loss: 128.233261\tlr: 0.000061\n",
      "Epoch: 42\tTraining Loss: 15.578549\tValidation Loss: 125.827166\tlr: 0.000060\n",
      "Epoch: 43\tTraining Loss: 15.296569\tValidation Loss: 123.553554\tlr: 0.000059\n",
      "Epoch: 44\tTraining Loss: 15.035371\tValidation Loss: 121.443400\tlr: 0.000058\n",
      "Epoch: 45\tTraining Loss: 14.793174\tValidation Loss: 119.491202\tlr: 0.000057\n",
      "Epoch: 46\tTraining Loss: 14.563419\tValidation Loss: 117.633309\tlr: 0.000056\n",
      "Epoch: 47\tTraining Loss: 14.339709\tValidation Loss: 115.829560\tlr: 0.000055\n",
      "Epoch: 48\tTraining Loss: 14.126259\tValidation Loss: 114.103997\tlr: 0.000054\n",
      "Epoch: 49\tTraining Loss: 13.920183\tValidation Loss: 112.441780\tlr: 0.000053\n",
      "Epoch: 50\tTraining Loss: 13.720381\tValidation Loss: 110.826085\tlr: 0.000053\n",
      "Epoch: 51\tTraining Loss: 13.525283\tValidation Loss: 109.252864\tlr: 0.000052\n",
      "Epoch: 52\tTraining Loss: 13.337217\tValidation Loss: 107.731934\tlr: 0.000051\n",
      "Epoch: 53\tTraining Loss: 13.152586\tValidation Loss: 106.242819\tlr: 0.000050\n",
      "Epoch: 54\tTraining Loss: 12.973305\tValidation Loss: 104.792785\tlr: 0.000049\n",
      "Epoch: 55\tTraining Loss: 12.797995\tValidation Loss: 103.379179\tlr: 0.000048\n",
      "Epoch: 56\tTraining Loss: 12.627214\tValidation Loss: 101.997724\tlr: 0.000047\n",
      "Epoch: 57\tTraining Loss: 12.459892\tValidation Loss: 100.648466\tlr: 0.000046\n",
      "Epoch: 58\tTraining Loss: 12.296897\tValidation Loss: 99.329936\tlr: 0.000045\n",
      "Epoch: 59\tTraining Loss: 12.136012\tValidation Loss: 98.032349\tlr: 0.000044\n",
      "Epoch: 60\tTraining Loss: 11.978692\tValidation Loss: 96.760012\tlr: 0.000043\n",
      "Epoch: 61\tTraining Loss: 11.824732\tValidation Loss: 95.518093\tlr: 0.000042\n",
      "Epoch: 62\tTraining Loss: 11.672630\tValidation Loss: 94.287912\tlr: 0.000041\n",
      "Epoch: 63\tTraining Loss: 11.523241\tValidation Loss: 93.082831\tlr: 0.000040\n",
      "Epoch: 64\tTraining Loss: 11.376407\tValidation Loss: 91.895233\tlr: 0.000039\n",
      "Epoch: 65\tTraining Loss: 11.232070\tValidation Loss: 90.731049\tlr: 0.000038\n",
      "Epoch: 66\tTraining Loss: 11.089569\tValidation Loss: 89.578292\tlr: 0.000037\n",
      "Epoch: 67\tTraining Loss: 10.949490\tValidation Loss: 88.448533\tlr: 0.000036\n",
      "Epoch: 68\tTraining Loss: 10.812564\tValidation Loss: 87.340974\tlr: 0.000035\n",
      "Epoch: 69\tTraining Loss: 10.676361\tValidation Loss: 86.242210\tlr: 0.000034\n",
      "Epoch: 70\tTraining Loss: 10.542523\tValidation Loss: 85.159762\tlr: 0.000034\n",
      "Epoch: 71\tTraining Loss: 10.411267\tValidation Loss: 84.100967\tlr: 0.000033\n",
      "Epoch: 72\tTraining Loss: 10.281775\tValidation Loss: 83.053663\tlr: 0.000032\n",
      "Epoch: 73\tTraining Loss: 10.154170\tValidation Loss: 82.024229\tlr: 0.000031\n",
      "Epoch: 74\tTraining Loss: 10.029001\tValidation Loss: 81.012018\tlr: 0.000030\n",
      "Epoch: 75\tTraining Loss: 9.905411\tValidation Loss: 80.014815\tlr: 0.000029\n",
      "Epoch: 76\tTraining Loss: 9.783908\tValidation Loss: 79.032362\tlr: 0.000028\n",
      "Epoch: 77\tTraining Loss: 9.664275\tValidation Loss: 78.067082\tlr: 0.000027\n",
      "Epoch: 78\tTraining Loss: 9.546372\tValidation Loss: 77.113692\tlr: 0.000026\n",
      "Epoch: 79\tTraining Loss: 9.430436\tValidation Loss: 76.178250\tlr: 0.000025\n",
      "Epoch: 80\tTraining Loss: 9.316363\tValidation Loss: 75.255872\tlr: 0.000024\n",
      "Epoch: 81\tTraining Loss: 9.203740\tValidation Loss: 74.347102\tlr: 0.000023\n",
      "Epoch: 82\tTraining Loss: 9.093661\tValidation Loss: 73.457196\tlr: 0.000022\n",
      "Epoch: 83\tTraining Loss: 8.985490\tValidation Loss: 72.584249\tlr: 0.000021\n",
      "Epoch: 84\tTraining Loss: 8.879012\tValidation Loss: 71.723419\tlr: 0.000020\n",
      "Epoch: 85\tTraining Loss: 8.774140\tValidation Loss: 70.877115\tlr: 0.000019\n",
      "Epoch: 86\tTraining Loss: 8.671048\tValidation Loss: 70.043656\tlr: 0.000018\n",
      "Epoch: 87\tTraining Loss: 8.569568\tValidation Loss: 69.224678\tlr: 0.000017\n",
      "Epoch: 88\tTraining Loss: 8.469817\tValidation Loss: 68.418307\tlr: 0.000016\n",
      "Epoch: 89\tTraining Loss: 8.371638\tValidation Loss: 67.625947\tlr: 0.000015\n",
      "Epoch: 90\tTraining Loss: 8.275296\tValidation Loss: 66.847158\tlr: 0.000015\n",
      "Epoch: 91\tTraining Loss: 8.180375\tValidation Loss: 66.081012\tlr: 0.000014\n",
      "Epoch: 92\tTraining Loss: 8.087329\tValidation Loss: 65.328996\tlr: 0.000013\n",
      "Epoch: 93\tTraining Loss: 7.995887\tValidation Loss: 64.590873\tlr: 0.000012\n",
      "Epoch: 94\tTraining Loss: 7.906030\tValidation Loss: 63.864659\tlr: 0.000011\n",
      "Epoch: 95\tTraining Loss: 7.817748\tValidation Loss: 63.151964\tlr: 0.000010\n",
      "Epoch: 96\tTraining Loss: 7.731221\tValidation Loss: 62.452798\tlr: 0.000009\n",
      "Epoch: 97\tTraining Loss: 7.646202\tValidation Loss: 61.766373\tlr: 0.000008\n",
      "Epoch: 98\tTraining Loss: 7.562819\tValidation Loss: 61.092652\tlr: 0.000007\n",
      "Epoch: 99\tTraining Loss: 7.480988\tValidation Loss: 60.431902\tlr: 0.000006\n",
      "Epoch: 100\tTraining Loss: 7.400774\tValidation Loss: 59.783874\tlr: 0.000005\n"
     ]
    }
   ],
   "source": [
    "# number of epochs to train the model\n",
    "n_epochs = 100\n",
    "train_losses = []\n",
    "valid_losses = []\n",
    "alpha = 1 # 正則化パラメータ\n",
    "\n",
    "def calc_li_loss(model, loss):\n",
    "    # パラメータのL1ノルムを損失関数に足す\n",
    "    l1 = torch.tensor(0., requires_grad=True)\n",
    "    for w in model.parameters():\n",
    "        l1 = l1 + torch.norm(w, 1)\n",
    "    l1_loss = loss + alpha*l1\n",
    "    return l1_loss\n",
    "\n",
    "\n",
    "for epoch in range(1, n_epochs+1):\n",
    "    train_batch_loss = 0.0\n",
    "    valid_batch_loss = 0.0\n",
    "    \n",
    "    for train_batch, valid_batch in zip(train_loader, valid_loader):\n",
    "        model.train()\n",
    "        data = train_batch.to(device=\"cuda\")\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(data)\n",
    "\n",
    "        train_loss = criterion(outputs, data)\n",
    "        l1_train_loss = calc_li_loss(model, train_loss)\n",
    "        l1_train_loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        train_batch_loss += l1_train_loss.item()\n",
    "\n",
    "        model.eval()\n",
    "        data = valid_batch.to(device=\"cuda\")\n",
    "        outputs = model(data)\n",
    "        valid_loss = criterion(outputs, data)\n",
    "        l1_valid_loss = calc_li_loss(model, valid_loss)\n",
    "        valid_batch_loss += l1_valid_loss.item()\n",
    "            \n",
    "    scheduler.step()\n",
    "\n",
    "    train_loss_avg = train_batch_loss/len(train_loader)\n",
    "    valid_loss_avg = valid_batch_loss/len(valid_loader)\n",
    "    train_losses.append(train_loss_avg)\n",
    "    valid_losses.append(valid_loss_avg)\n",
    "\n",
    "    # clear_output(wait=True)\n",
    "    print(f'Epoch: {epoch}\\tTraining Loss: {train_loss_avg:.6f}\\tValidation Loss: {valid_loss_avg:.6f}\\tlr: {optimizer.param_groups[0][\"lr\"]:.6f}')\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "        torch.save(model.state_dict(), f'./model/epoch_{epoch}.pth')\n",
    "\n",
    "        plt.plot(train_losses, label='Training loss')\n",
    "        plt.savefig(f'./model/train_loss_epoch_{epoch}.png')\n",
    "        plt.close()\n",
    "\n",
    "        plt.plot(valid_losses, label='Validation loss')\n",
    "        plt.savefig(f'./model/valid_loss_epoch_{epoch}.png')\n",
    "        plt.close()\n",
    "\n",
    "        plt.plot(train_losses, label='Training loss')\n",
    "        plt.plot(valid_losses, label='Validation loss')\n",
    "        plt.legend(frameon=False)\n",
    "        plt.savefig(f'./model/epoch_{epoch}.png')\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting the training loss\n",
    "plt.plot(range(1, n_epochs+1), train_losses, label='Train')\n",
    "plt.plot(range(1, n_epochs+1), valid_losses, label='Valid')\n",
    "plt.xlabel(\"Number of epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.042494\n"
     ]
    }
   ],
   "source": [
    "test_losses = 0\n",
    "for test_batch in test_loader:\n",
    "    model.eval()\n",
    "    data = test_batch.to(device=\"cuda\")\n",
    "    outputs = model(data)\n",
    "    test_loss = criterion(outputs, data)\n",
    "    test_losses += test_loss.item()\n",
    "print(f\"Test loss: {test_losses/len(test_loader):.6f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 2500x400 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8994e0ca858d44b0a2f901dc6a42cd49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='idx', options=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 1…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.interact_func(idx)>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataiter = iter(train_loader)\n",
    "datas = next(dataiter)\n",
    "\n",
    "model.eval()\n",
    "data = datas.to(device=\"cuda\")\n",
    "outputs = model(data)\n",
    "\n",
    "datas = datas.cpu().detach().numpy()\n",
    "outputs = outputs.cpu().detach().numpy()\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(25, 4))\n",
    "def interact_func(idx):\n",
    "    show_data(datas[idx].transpose(1,2,0).reshape(-1, chunk_size))\n",
    "    show_data(outputs[idx].transpose(1,2,0).reshape(-1, chunk_size))\n",
    "\n",
    "interact(interact_func, idx=range(datas.shape[0]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 2500x400 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c6c68fe0da5402f9306a2e476fe1a3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='idx', options=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 1…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.interact_func(idx)>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataiter = iter(test_loader)\n",
    "datas = next(dataiter)\n",
    "\n",
    "model.eval()\n",
    "data = datas.to(device=\"cuda\")\n",
    "outputs = model(data)\n",
    "\n",
    "datas = datas.cpu().detach().numpy()\n",
    "outputs = outputs.cpu().detach().numpy()\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(25, 4))\n",
    "\n",
    "def interact_func(idx):\n",
    "    show_data(datas[idx].transpose(1,2,0).reshape(-1, chunk_size))\n",
    "    show_data(outputs[idx].transpose(1,2,0).reshape(-1, chunk_size))\n",
    "\n",
    "interact(interact_func, idx=range(datas.shape[0]))\n",
    "\n",
    "# for idx in np.arange(5):\n",
    "#     show_data(datas[idx].transpose(1,2,0).reshape(-1,110))\n",
    "#     show_data(outputs[idx].transpose(1,2,0).reshape(-1,110))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.9000072e-06, 1.9000072e-06, 1.9000072e-06, ..., 1.9000072e-06,\n",
       "       1.9000072e-06, 1.9000072e-06], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[outputs!=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "noise_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
